{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7381\n",
      "[['./data/data/source_data/bumper/scratch\\\\205_101_10_0107f873-8e8a-43d6-94c5-703a77b87e08.jpg'\n",
      "  '1']\n",
      " ['./data/data/source_data/bumper/scratch\\\\205_101_10_01ba8ed7-8669-4af9-ad2f-7c73a124e769.jpg'\n",
      "  '1']\n",
      " ['./data/data/source_data/bumper/scratch\\\\205_101_10_0232027f-bfd3-460b-b92d-b14537879e9a.jpg'\n",
      "  '1']\n",
      " ...\n",
      " ['./data/data/source_data/frame/Seam_failure\\\\207_212_20_ff60575c-e8ea-4308-99ba-9ab01930c37a.jpg'\n",
      "  '0']\n",
      " ['./data/data/source_data/frame/Seam_failure\\\\207_212_20_ff8e6b23-6f57-47d2-b6c2-4fd4eb50e9f7.jpg'\n",
      "  '0']\n",
      " ['./data/data/source_data/frame/Seam_failure\\\\207_212_20_ffa0491f-762f-41be-8040-007d56f2d01f.jpg'\n",
      "  '0']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_bumper = np.genfromtxt('data/data/output/bumper/bumper_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_bumper = np.delete(data_bumper, 0 , axis = 0)\n",
    "\n",
    "data_door_ed = np.genfromtxt('data/data/output/door/door_ed_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_door_ed = np.delete(data_door_ed, 0 , axis = 0)\n",
    "data_door_scratch = np.genfromtxt('data/data/output/door/door_scratch_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_door_scratch = np.delete(data_door_scratch, 0 , axis = 0)\n",
    "\n",
    "data_fender = np.genfromtxt('data/data/output/fender/fender_ed_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_fender = np.delete(data_fender, 0 , axis = 0)\n",
    "\n",
    "data_frame_ed = np.genfromtxt('data/data/output/frame/frame_ed_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_frame_ed = np.delete(data_frame_ed, 0 , axis = 0)\n",
    "data_frame_hd = np.genfromtxt('data/data/output/frame/frame_hd_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_frame_hd = np.delete(data_frame_hd, 0 , axis = 0)\n",
    "data_frame_sealf = np.genfromtxt('data/data/output/frame/frame_sealf_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_frame_sealf = np.delete(data_frame_sealf, 0 , axis = 0)\n",
    "data_frame_seamf = np.genfromtxt('data/data/output/frame/frame_seamf_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_frame_seamf = np.delete(data_frame_seamf, 0 , axis = 0)\n",
    "\n",
    "data_1=np.array((data_bumper))\n",
    "data_2=np.array((data_door_ed))\n",
    "data_3=np.array((data_door_scratch))\n",
    "data_4=np.array((data_fender))\n",
    "data_5=np.array((data_frame_ed))\n",
    "data_6=np.array((data_frame_hd))\n",
    "data_7=np.array((data_frame_sealf))\n",
    "data_8=np.array((data_frame_seamf))\n",
    "\n",
    "data= np.concatenate((data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8), axis=0)  # axis=0: 배치 축\n",
    "print(len(data))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cuda 켜기(gpu 사용 확인)\n",
    "import torch\n",
    "tensor=torch.rand(3,4,dtype=torch.float32)\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tensor=tensor.to(device)\n",
    "tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1490  993 3214 3994 7348  383 4140 6249 1800 6298 6880 3303 4903 4911\n",
      " 1855 6032 4216 1688 5541 5764 5880 3874 4185 6409 3579 2010 6892 7246\n",
      " 4082 6897 2559 1469 3713 4842 2697   53 7012 3807 5393 1186 5272 3042\n",
      " 5602  878  685 2083 3864 1612 4915 6144 5034  775 1152 7189 4034 5584\n",
      " 3282 6049 2028 4476 3472  653 4666 1419 3104 2637 5852  667  834 4446\n",
      " 4929 5927 1487 1165 2700 5964 4978 5596 6059 6921  696  563 3919 4331\n",
      " 7214 6726 7369 3324 6664 6447 2702 3666 1862 3848 1853 4273 3598 5483\n",
      " 1111 6564  604 4762 5476 2058 3661 3282 3885 3959 6694 3986 4465 6117\n",
      " 2236 6727 4352 5705  634 6904  580 2205  332  639 1076 4263 3398 1077\n",
      " 5979 2458 6262 6302 5621 4714  813 2758  624  550  410 6115 4087 6589\n",
      " 5343 5529 5057 3969 1473 1073 4773 3578 5062  485  624 1380 5200 5104\n",
      " 6562 1061 2424 2745 3437 1482 1432 4299  198 1888 6237 2906 3209 1603\n",
      " 3380 5786 6738  970 1316 3563 3968 5376 5808  765   38 4044 6889 4193\n",
      " 4062 2457 4740 5448 4269 5056 6922 3018 1508 5411 3510  735 3601 5117\n",
      "   78 3684 1154 5395]\n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "\n",
    "data_num=200  #100개당 35초\n",
    "\n",
    "num=random.randint(len(data), size=data_num)\n",
    "\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진행현황: 0.0%\n",
      "진행현황: 5.0%\n",
      "진행현황: 10.0%\n",
      "진행현황: 15.0%\n",
      "진행현황: 20.0%\n",
      "진행현황: 25.0%\n",
      "진행현황: 30.0%\n",
      "진행현황: 35.0%\n",
      "진행현황: 40.0%\n",
      "진행현황: 45.0%\n",
      "진행현황: 50.0%\n",
      "진행현황: 55.00000000000001%\n",
      "진행현황: 60.0%\n",
      "진행현황: 65.0%\n",
      "진행현황: 70.0%\n",
      "진행현황: 75.0%\n",
      "진행현황: 80.0%\n",
      "진행현황: 85.0%\n",
      "진행현황: 90.0%\n",
      "진행현황: 95.0%\n",
      "(200, 2000, 4000, 3)\n",
      "(200, 1)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_1 = Image.open(data[0,0])\n",
    "\n",
    "a=np.array(img_1)\n",
    "x=np.expand_dims(a, axis=0)\n",
    "y=[]\n",
    "\n",
    "for i, i2 in enumerate(num):\n",
    "    img = Image.open(data[i2,0])\n",
    "    x_3=np.array(img)\n",
    "    x_4=np.expand_dims(x_3, axis=0)\n",
    "    x = np.concatenate((x, x_4), axis=0)  # axis=0: 배치 축\n",
    "    y.append(data[i2,1])\n",
    "    if i%10==0:\n",
    "        print(f'진행현황: {i/data_num*100}%')\n",
    "\n",
    "x=np.delete(x, 0 , axis = 0)\n",
    "y=np.array(y).reshape(data_num,1)\n",
    "#print(x)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# data sampling\n",
    "# x_sampled, y_sampled = resample(x, y, n_samples=100, random_state=42)\n",
    "\n",
    "# print(x_sampled.shape)\n",
    "# print(y_sampled.shape)\n",
    "\n",
    "\n",
    "# data split\n",
    "x_training, x_test, y_training, y_test = train_test_split(x, y, test_size=0.2, shuffle=True, stratify=y, random_state=34)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_training, y_training, test_size=0.2, shuffle=True, stratify=y_training, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 2000, 4000, 3)\n",
      "(128, 1)\n",
      "(32, 2000, 4000, 3)\n",
      "(32, 1)\n",
      "(40, 2000, 4000, 3)\n",
      "(40, 1)\n"
     ]
    }
   ],
   "source": [
    "# 사전 전처리 작성\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train type: <class 'numpy.ndarray'>, dtype: uint8\n",
      "y_train type: <class 'numpy.ndarray'>, dtype: <U1\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train type: {type(x_train)}, dtype: {x_train.dtype}\")\n",
    "print(f\"y_train type: {type(y_train)}, dtype: {y_train.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 11.4 GiB for an array with shape (128, 2000, 4000, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_train \u001b[38;5;241m=\u001b[39m x_train\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      2\u001b[0m x_valid \u001b[38;5;241m=\u001b[39m x_valid\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      3\u001b[0m x_test \u001b[38;5;241m=\u001b[39m x_test\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 11.4 GiB for an array with shape (128, 2000, 4000, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype(np.float32)\n",
    "x_valid = x_valid.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Labels: ['0' '1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 문자열 라벨 -> 정수 라벨로 변환\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)  # y_train이 [\"cat\", \"dog\"] 같은 문자열이라면\n",
    "y_valid = label_encoder.transform(y_valid)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "print(f\"Encoded Labels: {label_encoder.classes_}\")  # 라벨 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train type: <class 'numpy.ndarray'>, dtype: float32\n",
      "y_train type: <class 'numpy.ndarray'>, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train type: {type(x_train)}, dtype: {x_train.dtype}\")\n",
    "print(f\"y_train type: {type(y_train)}, dtype: {y_train.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] - Train Loss: 3.2866, Train Acc: 0.5312, Valid Loss: 0.7313, Valid Acc: 0.5000\n",
      "Epoch [2/10] - Train Loss: 2.8685, Train Acc: 0.5625, Valid Loss: 0.7035, Valid Acc: 0.5625\n",
      "Epoch [3/10] - Train Loss: 1.8886, Train Acc: 0.8125, Valid Loss: 0.6097, Valid Acc: 0.6250\n",
      "Epoch [4/10] - Train Loss: 1.3182, Train Acc: 0.9062, Valid Loss: 0.5951, Valid Acc: 0.6250\n",
      "Epoch [5/10] - Train Loss: 0.6312, Train Acc: 0.9844, Valid Loss: 0.6366, Valid Acc: 0.5625\n",
      "Epoch [6/10] - Train Loss: 0.2472, Train Acc: 0.9844, Valid Loss: 0.8206, Valid Acc: 0.5625\n",
      "Epoch [7/10] - Train Loss: 0.1119, Train Acc: 0.9844, Valid Loss: 0.6989, Valid Acc: 0.6875\n",
      "Epoch [8/10] - Train Loss: 0.0304, Train Acc: 1.0000, Valid Loss: 0.7540, Valid Acc: 0.8125\n",
      "Epoch [9/10] - Train Loss: 0.0289, Train Acc: 1.0000, Valid Loss: 0.9460, Valid Acc: 0.7500\n",
      "Epoch [10/10] - Train Loss: 0.0102, Train Acc: 1.0000, Valid Loss: 1.3079, Valid Acc: 0.6875\n",
      "Test Accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "\n",
    "# 1. 데이터 전처리 변환 정의 (이미지 크기 조정 및 정규화)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # (H, W, C) -> (C, H, W)로 변환\n",
    "    transforms.Resize((224, 224)),  # Swin Transformer의 입력 크기\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet 정규화 값\n",
    "])\n",
    "\n",
    "# 2. 데이터 전처리 함수 정의\n",
    "def preprocess_data(x_data, y_data, transform):\n",
    "    # (배치수, 높이, 너비, 채널) -> (배치수, 채널, 높이, 너비)로 변환\n",
    "    x_data_transformed = []\n",
    "    for img in x_data:\n",
    "        img_transformed = transform(img)  # 하나씩 전처리 적용\n",
    "        x_data_transformed.append(img_transformed)\n",
    "    x_data_transformed = torch.stack(x_data_transformed)  # 리스트를 텐서로 변환\n",
    "    y_data = torch.tensor(y_data, dtype=torch.long)  # 라벨도 텐서로 변환\n",
    "    return x_data_transformed, y_data\n",
    "\n",
    "# 3. 전처리된 데이터 로드\n",
    "x_train_processed, y_train_processed = preprocess_data(x_train, y_train, transform)\n",
    "x_valid_processed, y_valid_processed = preprocess_data(x_valid, y_valid, transform)\n",
    "x_test_processed, y_test_processed = preprocess_data(x_test, y_test, transform)\n",
    "\n",
    "# 4. DataLoader 생성\n",
    "def create_dataloader(x_data, y_data, batch_size=32, shuffle=True):\n",
    "    dataset = TensorDataset(x_data, y_data)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = create_dataloader(x_train_processed, y_train_processed, batch_size=batch_size)\n",
    "valid_loader = create_dataloader(x_valid_processed, y_valid_processed, batch_size=batch_size)\n",
    "test_loader = create_dataloader(x_test_processed, y_test_processed, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 5. Swin Transformer 모델 불러오기\n",
    "model = timm.create_model(\"swin_tiny_patch4_window7_224\", pretrained=True, num_classes=len(set(y_train)))\n",
    "\n",
    "# 6. 학습 준비\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # 손실 함수\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)  # 최적화 알고리즘\n",
    "\n",
    "# 7. 학습 함수 정의\n",
    "def train_model(model, train_loader, valid_loader, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "\n",
    "        train_acc = correct / len(train_loader.dataset)\n",
    "\n",
    "        # 검증\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        valid_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for x_val, y_val in valid_loader:\n",
    "                x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "                outputs = model(x_val)\n",
    "                loss = criterion(outputs, y_val)\n",
    "                valid_loss += loss.item()\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                valid_correct += (preds == y_val).sum().item()\n",
    "\n",
    "        valid_acc = valid_correct / len(valid_loader.dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "              f\"Valid Loss: {valid_loss:.4f}, Valid Acc: {valid_acc:.4f}\")\n",
    "\n",
    "# 8. 학습 실행\n",
    "train_model(model, train_loader, valid_loader, num_epochs=10)\n",
    "\n",
    "# 9. 테스트 정확도 평가\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x_test_batch, y_test_batch in test_loader:\n",
    "            x_test_batch, y_test_batch = x_test_batch.to(device), y_test_batch.to(device)\n",
    "            outputs = model(x_test_batch)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            test_correct += (preds == y_test_batch).sum().item()\n",
    "    test_acc = test_correct / len(test_loader.dataset)\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.89      0.73      0.80        11\n",
      "     Class 1       0.73      0.89      0.80         9\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.81      0.81      0.80        20\n",
      "weighted avg       0.82      0.80      0.80        20\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[8 3]\n",
      " [1 8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "# 1. 테스트 데이터에 대해 예측값 생성\n",
    "def get_predictions(model, test_loader):\n",
    "    model.eval()  # 평가 모드 설정\n",
    "    y_true = []  # 실제 라벨\n",
    "    y_pred = []  # 모델 예측값\n",
    "\n",
    "    with torch.no_grad():  # 그래디언트 계산 비활성화\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            outputs = model(x_batch)  # 모델 예측\n",
    "            preds = outputs.argmax(dim=1)  # 가장 높은 확률의 클래스를 선택\n",
    "            y_true.extend(y_batch.cpu().numpy())  # 실제 라벨을 NumPy 배열로 변환\n",
    "            y_pred.extend(preds.cpu().numpy())  # 예측값을 NumPy 배열로 변환\n",
    "\n",
    "    return np.array(y_true), np.array(y_pred)\n",
    "\n",
    "# 2. 테스트 데이터에 대한 예측 수행\n",
    "y_true, y_pred = get_predictions(model, test_loader)\n",
    "\n",
    "# 3. 평가 결과 출력 (scikit-learn 사용)\n",
    "# 정확도\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "\n",
    "# 분류 보고서\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Class 0\", \"Class 1\"]))\n",
    "\n",
    "# 혼동 행렬\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(x_test_processed.shape)\n",
    "print(x_train_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 손실 감소 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loss)\n",
    "plt.grid()\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## data evaluation\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, roc_auc_score\n\u001b[1;32m----> 4\u001b[0m pred\u001b[38;5;241m=\u001b[39mmodel(x_test_processed)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 혼동 행렬\u001b[39;00m\n\u001b[0;32m      8\u001b[0m confmat \u001b[38;5;241m=\u001b[39m confusion_matrix(y_true\u001b[38;5;241m=\u001b[39my_test_processed, y_pred\u001b[38;5;241m=\u001b[39mpred)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\timm\\models\\swin_transformer.py:838\u001b[0m, in \u001b[0;36mSwinTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 838\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_features(x)\n\u001b[0;32m    839\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_head(x)\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\timm\\models\\swin_transformer.py:829\u001b[0m, in \u001b[0;36mSwinTransformer.forward_features\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 829\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_embed(x)\n\u001b[0;32m    830\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(x)\n\u001b[0;32m    831\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\timm\\layers\\patch_embed.py:131\u001b[0m, in \u001b[0;36mPatchEmbed.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    129\u001b[0m     pad_w \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m W \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    130\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(x, (\u001b[38;5;241m0\u001b[39m, pad_w, \u001b[38;5;241m0\u001b[39m, pad_h))\n\u001b[1;32m--> 131\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(x)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten:\n\u001b[0;32m    133\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# NCHW -> NLC\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[0;32m    551\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "## data evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "pred=model(x_test_processed)\n",
    "\n",
    "\n",
    "# 혼동 행렬\n",
    "confmat = confusion_matrix(y_true=y_test_processed, y_pred=pred)\n",
    "print('혼동 행렬: ', confmat)\n",
    "\n",
    "\n",
    "# 정확도\n",
    "accuracy=accuracy_score(y_true=y_test_processed, y_pred=pred)\n",
    "print('정확도: ', accuracy)\n",
    "\n",
    "\n",
    "# 정밀도(precision)\n",
    "precision = precision_score(y_true=y_test_processed, y_pred=pred)\n",
    "print('정밀도: ', precision)\n",
    "\n",
    "\n",
    "# 재현율(recall)\n",
    "recall = recall_score(y_true=y_test_processed, y_pred=pred)\n",
    "print('재현율: ', recall)\n",
    "\n",
    "\n",
    "# roc auc\n",
    "fpr, tpr, _ = roc_curve(y_true=y_test_processed, y_pred=pred)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('FP Rate')\n",
    "plt.ylabel('TP Rate')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('auc 점수: ', roc_auc_score(y_test_processed, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
