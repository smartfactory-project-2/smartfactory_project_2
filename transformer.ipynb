{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7381\n",
      "[['./data/data/source_data/bumper/scratch\\\\205_101_10_0107f873-8e8a-43d6-94c5-703a77b87e08.jpg'\n",
      "  '1']\n",
      " ['./data/data/source_data/bumper/scratch\\\\205_101_10_01ba8ed7-8669-4af9-ad2f-7c73a124e769.jpg'\n",
      "  '1']\n",
      " ['./data/data/source_data/bumper/scratch\\\\205_101_10_0232027f-bfd3-460b-b92d-b14537879e9a.jpg'\n",
      "  '1']\n",
      " ...\n",
      " ['./data/data/source_data/frame/Seam_failure\\\\207_212_20_ff60575c-e8ea-4308-99ba-9ab01930c37a.jpg'\n",
      "  '0']\n",
      " ['./data/data/source_data/frame/Seam_failure\\\\207_212_20_ff8e6b23-6f57-47d2-b6c2-4fd4eb50e9f7.jpg'\n",
      "  '0']\n",
      " ['./data/data/source_data/frame/Seam_failure\\\\207_212_20_ffa0491f-762f-41be-8040-007d56f2d01f.jpg'\n",
      "  '0']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_bumper = np.genfromtxt('data/data/output/bumper/bumper_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_bumper = np.delete(data_bumper, 0 , axis = 0)\n",
    "\n",
    "data_door_ed = np.genfromtxt('data/data/output/door/door_ed_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_door_ed = np.delete(data_door_ed, 0 , axis = 0)\n",
    "data_door_scratch = np.genfromtxt('data/data/output/door/door_scratch_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_door_scratch = np.delete(data_door_scratch, 0 , axis = 0)\n",
    "\n",
    "data_fender = np.genfromtxt('data/data/output/fender/fender_ed_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_fender = np.delete(data_fender, 0 , axis = 0)\n",
    "\n",
    "data_frame_ed = np.genfromtxt('data/data/output/frame/frame_ed_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_frame_ed = np.delete(data_frame_ed, 0 , axis = 0)\n",
    "data_frame_hd = np.genfromtxt('data/data/output/frame/frame_hd_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_frame_hd = np.delete(data_frame_hd, 0 , axis = 0)\n",
    "data_frame_sealf = np.genfromtxt('data/data/output/frame/frame_sealf_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_frame_sealf = np.delete(data_frame_sealf, 0 , axis = 0)\n",
    "data_frame_seamf = np.genfromtxt('data/data/output/frame/frame_seamf_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_frame_seamf = np.delete(data_frame_seamf, 0 , axis = 0)\n",
    "\n",
    "data_1=np.array((data_bumper))\n",
    "data_2=np.array((data_door_ed))\n",
    "data_3=np.array((data_door_scratch))\n",
    "data_4=np.array((data_fender))\n",
    "data_5=np.array((data_frame_ed))\n",
    "data_6=np.array((data_frame_hd))\n",
    "data_7=np.array((data_frame_sealf))\n",
    "data_8=np.array((data_frame_seamf))\n",
    "\n",
    "data= np.concatenate((data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8), axis=0)  # axis=0: 배치 축\n",
    "print(len(data))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cuda 켜기(gpu 사용 확인)\n",
    "import torch\n",
    "tensor=torch.rand(3,4,dtype=torch.float32)\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tensor=tensor.to(device)\n",
    "tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4309 5628 6106 1908 6601 2923 7149 6679 3228 5275 4073 7152 2250 1056\n",
      " 1322 2299  643 5915 6086 2534 3345 2087 2865  700 5009 3551 2252 3099\n",
      " 6196 4175 6859 6639 3765  709 6429  871 1010 2281   32  516 7316 2215\n",
      " 1724 1315 5055 4011   86 4561 7340 4571 2583 6919 4523 3716 1915 4749\n",
      " 1001 6626  564 4383  605 6152 6961 2802 4030 1993 4987 7229  114  778\n",
      " 6804 2161 4757 3513 4014 2346 6604 2838  391 2362 5338 7053 6310 3330\n",
      " 6041 6401 7207 5893 6613 4765  801  982 3691 1212   82 4849 4684 4533\n",
      " 7205  601 6448 1692 7038 4036 3147 1996 3113 6322  608 6669 3809 2974\n",
      " 4462 5836 1503 4425  495 7024 1712 1731 6301  516 1995 7266   22 4784\n",
      " 7083 7102 7096 7246 3601 7242 1705 3126 6995 5447 3350 4190 3635 6529\n",
      " 7141  434 1015 6345 3108 2214 6799 6773 2572  242 4293 2464 2831 5908\n",
      " 1762 3190 2352  193 5256 5136 6288 6859 2759 6507 2555 1448 7036 4248\n",
      " 1586 2605 4605 2392 7341 3553 1470 2100  677 1233 6199 1242 4278 6627\n",
      " 6862 4351 5997 3911 3396 4559 1949 5697   24 2450 7114 3366  208 3944\n",
      " 7053  307 5877 4123  638 6546 1604  728 5963 4814 2228 6382 3149 5702\n",
      " 2344 7371 6730  797 7107 1897 6329 3041 3377 2587 2537 7249 4943 2261\n",
      "  855 6699 5231 4169 2372 5773 7104 2291 1131 4348 2200 7334 2410 4411\n",
      " 2847 5446 5864 3684 3782 1394 3246  380 5174 4789 1539 3889 6572  780\n",
      " 7360 6611 7168 4599 7170 2539 3851 5514 1005 4015 3032  496 1111 1510\n",
      " 6461 3156 3399  246   40 6870 1665 4237 1352  963  690 5250 5475 7007\n",
      " 7352 5364 6554 5626 2489 5430 5851 1198 2020 4693 1891 5631 7147 4289\n",
      " 4626 1798 2260 2673 4392 3483 4376  262 6736 5468 6705 6051 7258 6922\n",
      " 4765 4725  157  201 2474 1870 5303 5906 1814 7103 4988 1731 1362 3615\n",
      " 5001 6651 6507  255 2774 1741 1844 6449  401 6511 6371 2235   49 5202\n",
      "  952 2075 2317 4132 1381 1450 6930 5869 5355 3956 5636 6882  243 1321\n",
      "  540 1128 1812 5203 2940 3610 6086 2798 4645 1420  542  192 4491 2206\n",
      "  758  863 6464 6150 5351 5290 3419  716 5584 6479 5730 5037 7015 3557\n",
      " 2668 5114 6252 4262 2945 2448 3296 5675 7308 4778 4984 3890 2427  224\n",
      " 7273 7013 3802 1695 6727 6074 6198 6795 4648 6251 3706 6918 1743 1400\n",
      " 4270 5413 1707 7075 5151 1550 1643 4066 1627 3500 4114 2675  224  897\n",
      " 6628 6162 5926 5210  449 5930 1650 5447 4300 6499 4510 1787 3256 3209\n",
      " 5558 3324  369 5896 3810 3723 2791 4521 3487 1043 7064 6458 7040 2034\n",
      " 6586 1223 1160 6576 1308 3689 1467  375 4095 2383  823  948  458 5957\n",
      " 1083 6143 4488 1710  188 5920 2572 4382 4406 5938  357 7279 5876 3428\n",
      " 6815 5965 7021 6413 2002 1903 4913 4632 3822 5938 3834 2503 1271  991\n",
      "  465 4706  814 3180 5825  297 6333 1602 4932 2712  600 4292 4683 1391\n",
      " 5594 3910 4657 1601 3478 7083 6323 4514 5054  572 3403 6893 4903 5855\n",
      " 4182  650 2804 6769 6790 3300 3059 3068 2256 1053 3469 5543  844 2297\n",
      " 1721 3331  575 2101 3500 7092 6478 6652 1424 5492 2461  317 4382 6199\n",
      " 4225  571 2587 6551 2937 5904 6079 3672  363 6894   28 4279  916 2906\n",
      "  429 3129 2244 2521 6652 1522 2982 2713  945 6533  675 4151 5383 6829\n",
      " 4865  797 3708 2670  667 3350 5344 5721 1003  943 3823 3657 1481 2889\n",
      " 6783 1713 2068  402 4556 5488 3279  166 5330 4140 4092 2339 3388 5121\n",
      " 3375 3889 1570 6178 2889 2868 2499 3692 2556 5553 2853 7353 5862 7331\n",
      " 4933 6347 5690 6455 6143  123 4131 4036 1749 6770 5671 1624 5063 1116\n",
      " 6634 6832 5343 4724  268 6277 5405 6789 1669 3777  605 1803 6758 5700\n",
      " 1205 3305 2073 2465 4069  396 3251 5388 2061 5083 6112 2414 5234   26\n",
      " 5627 3159 6055 6688 4682 4695 4696 1529 2406 6977 2350 1126 7327 5283\n",
      "  301 3665 4216 4384 6914 5032 5179  977 6998 1236 3096 5670 2593 5314\n",
      " 3368 5314 6157 6003  134 2442  719 5227 3570 5548 5803 1133 2941  361\n",
      " 3399 3817 6687 3936 7214 7368 6278 4989 6966  847 5733 1252 6876 2324\n",
      " 4403 1279 4161 5671 7138 6045 5825  350  962 1158 4326  565 5654 2406\n",
      " 3319 6384 3031 6085 5494 6671  633 5478 1298 4229 2639 1613 2059 4259\n",
      " 2259 5927 3710  512 6072 4293 4972 5705 3959 6805 2464 4949 1037 7182\n",
      " 1195 3268  408  895 1226 2521 2209 4977 4744 4791 2040 3623 1351 1704\n",
      " 3490 3714 4162 1626 1601 7147 3067 2450 6573 7360 6977 3561 4038 3506\n",
      " 2125 6690 1064 2761 1853 1152 2449 1004 5204 4818 1477 5067 7276 5226\n",
      " 2224  401 6557 4405 6392 6720  589  852 6998 7019 7058 6339  334   68\n",
      " 6183 5494 2510 3190 6098 6847  842 1655 6857 3503 6891  852 3113 5857\n",
      " 4726  543 4352 2579   25 1172 4881 6970 3124 1312 5162 6692 3479  920\n",
      "  286  916 1395 5450   38 5033 2683 2139 3516  635 6522 5344 5505 5608\n",
      " 2699 4824 5992  266  443 7013  309 1628 2874 2572  650 2034 6813 4097\n",
      " 6563  812 5317 1915 6030 3914 5628 3551 3536 4082 6800 1742 2403  102\n",
      " 3845 3331 1806 5900 1024 5917 2967 2281 6372 5276 2470 3621 4368  819\n",
      " 5157 1495 2203 5199  886 4056 7128 1665 4798 6025 4860 5119 1916 2186\n",
      " 5285 6570 4215 6796  399 4154 7226 7127 1102 5032 1411 4758  940 1585\n",
      "  451  695 5133 5407 3764 6780 2496  251 3818 1352 5892 3049 4400 2046\n",
      " 6644 3344 4786 7292 3055 2989 4985 4718 7274 7127 5187  558 4883 7091\n",
      " 2903 3937 6815 6458 1283 1385 6224 4306 4886 3927 2914 2268 2346 3339\n",
      " 1480 5451 6802 2127 5740 2515  518 6105 4585  413 2064 1352 1738  490\n",
      " 3814 1509 2447 4132 2060 6781 4021 4678 2639 7372 6433 3854 1443 2845\n",
      " 1206 1609   92 1634 4033   38]\n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "\n",
    "data_num=1000  #100개당 35초\n",
    "\n",
    "num=random.randint(len(data), size=data_num)\n",
    "\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진행현황: 0.0%\n",
      "진행현황: 1.0%\n",
      "진행현황: 2.0%\n",
      "진행현황: 3.0%\n",
      "진행현황: 4.0%\n",
      "진행현황: 5.0%\n",
      "진행현황: 6.0%\n",
      "진행현황: 7.000000000000001%\n",
      "진행현황: 8.0%\n",
      "진행현황: 9.0%\n",
      "진행현황: 10.0%\n",
      "진행현황: 11.0%\n",
      "진행현황: 12.0%\n",
      "진행현황: 13.0%\n",
      "진행현황: 14.000000000000002%\n",
      "진행현황: 15.0%\n",
      "진행현황: 16.0%\n",
      "진행현황: 17.0%\n",
      "진행현황: 18.0%\n",
      "진행현황: 19.0%\n",
      "진행현황: 20.0%\n",
      "진행현황: 21.0%\n",
      "진행현황: 22.0%\n",
      "진행현황: 23.0%\n",
      "진행현황: 24.0%\n",
      "진행현황: 25.0%\n",
      "진행현황: 26.0%\n",
      "진행현황: 27.0%\n",
      "진행현황: 28.000000000000004%\n",
      "진행현황: 28.999999999999996%\n",
      "진행현황: 30.0%\n",
      "진행현황: 31.0%\n",
      "진행현황: 32.0%\n",
      "진행현황: 33.0%\n",
      "진행현황: 34.0%\n",
      "진행현황: 35.0%\n",
      "진행현황: 36.0%\n",
      "진행현황: 37.0%\n",
      "진행현황: 38.0%\n",
      "진행현황: 39.0%\n",
      "진행현황: 40.0%\n",
      "진행현황: 41.0%\n",
      "진행현황: 42.0%\n",
      "진행현황: 43.0%\n",
      "진행현황: 44.0%\n",
      "진행현황: 45.0%\n",
      "진행현황: 46.0%\n",
      "진행현황: 47.0%\n",
      "진행현황: 48.0%\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 11.0 GiB for an array with shape (492, 2000, 4000, 3) and data type uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m x_3\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(img)\n\u001b[0;32m     12\u001b[0m x_4\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mexpand_dims(x_3, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((x, x_4), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# axis=0: 배치 축\u001b[39;00m\n\u001b[0;32m     14\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(data[i2,\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 11.0 GiB for an array with shape (492, 2000, 4000, 3) and data type uint8"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_1 = Image.open(data[0,0])\n",
    "\n",
    "a=np.array(img_1)\n",
    "x=np.expand_dims(a, axis=0)\n",
    "y=[]\n",
    "\n",
    "for i, i2 in enumerate(num):\n",
    "    img = Image.open(data[i2,0])\n",
    "    x_3=np.array(img)\n",
    "    x_4=np.expand_dims(x_3, axis=0)\n",
    "    x = np.concatenate((x, x_4), axis=0)  # axis=0: 배치 축\n",
    "    y.append(data[i2,1])\n",
    "    if i%10==0:\n",
    "        print(f'진행현황: {i/data_num*100}%')\n",
    "\n",
    "x=np.delete(x, 0 , axis = 0)\n",
    "y=np.array(y).reshape(data_num,1)\n",
    "#print(x)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# data sampling\n",
    "# x_sampled, y_sampled = resample(x, y, n_samples=100, random_state=42)\n",
    "\n",
    "# print(x_sampled.shape)\n",
    "# print(y_sampled.shape)\n",
    "\n",
    "\n",
    "# data split\n",
    "x_training, x_test, y_training, y_test = train_test_split(x, y, test_size=0.2, shuffle=True, stratify=y, random_state=34)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_training, y_training, test_size=0.2, shuffle=True, stratify=y_training, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 2000, 4000, 3)\n",
      "(192, 1)\n",
      "(48, 2000, 4000, 3)\n",
      "(48, 1)\n",
      "(60, 2000, 4000, 3)\n",
      "(60, 1)\n"
     ]
    }
   ],
   "source": [
    "# 사전 전처리 작성\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train type: <class 'numpy.ndarray'>, dtype: uint8\n",
      "y_train type: <class 'numpy.ndarray'>, dtype: <U1\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train type: {type(x_train)}, dtype: {x_train.dtype}\")\n",
    "print(f\"y_train type: {type(y_train)}, dtype: {y_train.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 17.2 GiB for an array with shape (192, 2000, 4000, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_train \u001b[38;5;241m=\u001b[39m x_train\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      2\u001b[0m x_valid \u001b[38;5;241m=\u001b[39m x_valid\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      3\u001b[0m x_test \u001b[38;5;241m=\u001b[39m x_test\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 17.2 GiB for an array with shape (192, 2000, 4000, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype(np.float32)\n",
    "x_valid = x_valid.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Labels: ['0' '1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 문자열 라벨 -> 정수 라벨로 변환\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)  # y_train이 [\"cat\", \"dog\"] 같은 문자열이라면\n",
    "y_valid = label_encoder.transform(y_valid)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "print(f\"Encoded Labels: {label_encoder.classes_}\")  # 라벨 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train type: <class 'numpy.ndarray'>, dtype: uint8\n",
      "y_train type: <class 'numpy.ndarray'>, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train type: {type(x_train)}, dtype: {x_train.dtype}\")\n",
    "print(f\"y_train type: {type(y_train)}, dtype: {y_train.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] - Train Loss: 6.6931, Train Acc: 0.6875, Valid Loss: 1.4764, Valid Acc: 0.7708\n",
      "Epoch [2/10] - Train Loss: 3.9542, Train Acc: 0.8802, Valid Loss: 0.8898, Valid Acc: 0.8958\n",
      "Epoch [3/10] - Train Loss: 1.2271, Train Acc: 0.9792, Valid Loss: 0.7906, Valid Acc: 0.8542\n",
      "Epoch [4/10] - Train Loss: 0.5901, Train Acc: 0.9896, Valid Loss: 1.2361, Valid Acc: 0.8750\n",
      "Epoch [5/10] - Train Loss: 0.0839, Train Acc: 1.0000, Valid Loss: 1.5937, Valid Acc: 0.8542\n",
      "Epoch [6/10] - Train Loss: 0.0272, Train Acc: 1.0000, Valid Loss: 1.4393, Valid Acc: 0.8542\n",
      "Epoch [7/10] - Train Loss: 0.0119, Train Acc: 1.0000, Valid Loss: 2.1857, Valid Acc: 0.8750\n",
      "Epoch [8/10] - Train Loss: 0.0181, Train Acc: 1.0000, Valid Loss: 1.5737, Valid Acc: 0.8958\n",
      "Epoch [9/10] - Train Loss: 0.0114, Train Acc: 1.0000, Valid Loss: 2.1044, Valid Acc: 0.8750\n",
      "Epoch [10/10] - Train Loss: 0.0079, Train Acc: 1.0000, Valid Loss: 1.4927, Valid Acc: 0.8958\n",
      "Test Accuracy: 0.8667\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "\n",
    "# 1. 데이터 전처리 변환 정의 (이미지 크기 조정 및 정규화)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # (H, W, C) -> (C, H, W)로 변환\n",
    "    transforms.Resize((224, 224)),  # Swin Transformer의 입력 크기\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet 정규화 값\n",
    "])\n",
    "\n",
    "# 2. 데이터 전처리 함수 정의\n",
    "def preprocess_data(x_data, y_data, transform):\n",
    "    # (배치수, 높이, 너비, 채널) -> (배치수, 채널, 높이, 너비)로 변환\n",
    "    x_data_transformed = []\n",
    "    for img in x_data:\n",
    "        img_transformed = transform(img)  # 하나씩 전처리 적용\n",
    "        x_data_transformed.append(img_transformed)\n",
    "    x_data_transformed = torch.stack(x_data_transformed)  # 리스트를 텐서로 변환\n",
    "    y_data = torch.tensor(y_data, dtype=torch.long)  # 라벨도 텐서로 변환\n",
    "    return x_data_transformed, y_data\n",
    "\n",
    "# 3. 전처리된 데이터 로드\n",
    "x_train_processed, y_train_processed = preprocess_data(x_train, y_train, transform)\n",
    "x_valid_processed, y_valid_processed = preprocess_data(x_valid, y_valid, transform)\n",
    "x_test_processed, y_test_processed = preprocess_data(x_test, y_test, transform)\n",
    "\n",
    "# 4. DataLoader 생성\n",
    "def create_dataloader(x_data, y_data, batch_size=32, shuffle=True):\n",
    "    dataset = TensorDataset(x_data, y_data)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = create_dataloader(x_train_processed, y_train_processed, batch_size=batch_size)\n",
    "valid_loader = create_dataloader(x_valid_processed, y_valid_processed, batch_size=batch_size)\n",
    "test_loader = create_dataloader(x_test_processed, y_test_processed, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 5. Swin Transformer 모델 불러오기\n",
    "model = timm.create_model(\"swin_tiny_patch4_window7_224\", pretrained=True, num_classes=len(set(y_train)))\n",
    "\n",
    "# 6. 학습 준비\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # 손실 함수\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)  # 최적화 알고리즘\n",
    "\n",
    "# 7. 학습 함수 정의\n",
    "def train_model(model, train_loader, valid_loader, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "\n",
    "        train_acc = correct / len(train_loader.dataset)\n",
    "\n",
    "        # 검증\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        valid_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for x_val, y_val in valid_loader:\n",
    "                x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "                outputs = model(x_val)\n",
    "                loss = criterion(outputs, y_val)\n",
    "                valid_loss += loss.item()\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                valid_correct += (preds == y_val).sum().item()\n",
    "\n",
    "        valid_acc = valid_correct / len(valid_loader.dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "              f\"Valid Loss: {valid_loss:.4f}, Valid Acc: {valid_acc:.4f}\")\n",
    "\n",
    "# 8. 학습 실행\n",
    "train_model(model, train_loader, valid_loader, num_epochs=10)\n",
    "\n",
    "# 9. 테스트 정확도 평가\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x_test_batch, y_test_batch in test_loader:\n",
    "            x_test_batch, y_test_batch = x_test_batch.to(device), y_test_batch.to(device)\n",
    "            outputs = model(x_test_batch)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            test_correct += (preds == y_test_batch).sum().item()\n",
    "    test_acc = test_correct / len(test_loader.dataset)\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8667\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.89      0.89      0.89        35\n",
      "     Class 1       0.84      0.84      0.84        25\n",
      "\n",
      "    accuracy                           0.87        60\n",
      "   macro avg       0.86      0.86      0.86        60\n",
      "weighted avg       0.87      0.87      0.87        60\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[31  4]\n",
      " [ 4 21]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "# 1. 테스트 데이터에 대해 예측값 생성\n",
    "def get_predictions(model, test_loader):\n",
    "    model.eval()  # 평가 모드 설정\n",
    "    y_true = []  # 실제 라벨\n",
    "    y_pred = []  # 모델 예측값\n",
    "\n",
    "    with torch.no_grad():  # 그래디언트 계산 비활성화\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            outputs = model(x_batch)  # 모델 예측\n",
    "            preds = outputs.argmax(dim=1)  # 가장 높은 확률의 클래스를 선택\n",
    "            y_true.extend(y_batch.cpu().numpy())  # 실제 라벨을 NumPy 배열로 변환\n",
    "            y_pred.extend(preds.cpu().numpy())  # 예측값을 NumPy 배열로 변환\n",
    "\n",
    "    return np.array(y_true), np.array(y_pred)\n",
    "\n",
    "# 2. 테스트 데이터에 대한 예측 수행\n",
    "y_true, y_pred = get_predictions(model, test_loader)\n",
    "\n",
    "# 3. 평가 결과 출력 (scikit-learn 사용)\n",
    "# 정확도\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "\n",
    "# 분류 보고서\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Class 0\", \"Class 1\"]))\n",
    "\n",
    "# 혼동 행렬\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3, 224, 224])\n",
      "torch.Size([64, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(x_test_processed.shape)\n",
    "print(x_train_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 손실 감소 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loss)\n",
    "plt.grid()\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## data evaluation\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, roc_auc_score\n\u001b[1;32m----> 4\u001b[0m pred\u001b[38;5;241m=\u001b[39mmodel(x_test_processed)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 혼동 행렬\u001b[39;00m\n\u001b[0;32m      8\u001b[0m confmat \u001b[38;5;241m=\u001b[39m confusion_matrix(y_true\u001b[38;5;241m=\u001b[39my_test_processed, y_pred\u001b[38;5;241m=\u001b[39mpred)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\timm\\models\\swin_transformer.py:838\u001b[0m, in \u001b[0;36mSwinTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 838\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_features(x)\n\u001b[0;32m    839\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_head(x)\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\timm\\models\\swin_transformer.py:829\u001b[0m, in \u001b[0;36mSwinTransformer.forward_features\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 829\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_embed(x)\n\u001b[0;32m    830\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(x)\n\u001b[0;32m    831\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\timm\\layers\\patch_embed.py:131\u001b[0m, in \u001b[0;36mPatchEmbed.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    129\u001b[0m     pad_w \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m W \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    130\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(x, (\u001b[38;5;241m0\u001b[39m, pad_w, \u001b[38;5;241m0\u001b[39m, pad_h))\n\u001b[1;32m--> 131\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(x)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten:\n\u001b[0;32m    133\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# NCHW -> NLC\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[0;32m    551\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "## data evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "pred=model(x_test_processed)\n",
    "\n",
    "\n",
    "# 혼동 행렬\n",
    "confmat = confusion_matrix(y_true=y_test_processed, y_pred=pred)\n",
    "print('혼동 행렬: ', confmat)\n",
    "\n",
    "\n",
    "# 정확도\n",
    "accuracy=accuracy_score(y_true=y_test_processed, y_pred=pred)\n",
    "print('정확도: ', accuracy)\n",
    "\n",
    "\n",
    "# 정밀도(precision)\n",
    "precision = precision_score(y_true=y_test_processed, y_pred=pred)\n",
    "print('정밀도: ', precision)\n",
    "\n",
    "\n",
    "# 재현율(recall)\n",
    "recall = recall_score(y_true=y_test_processed, y_pred=pred)\n",
    "print('재현율: ', recall)\n",
    "\n",
    "\n",
    "# roc auc\n",
    "fpr, tpr, _ = roc_curve(y_true=y_test_processed, y_pred=pred)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('FP Rate')\n",
    "plt.ylabel('TP Rate')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('auc 점수: ', roc_auc_score(y_test_processed, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
